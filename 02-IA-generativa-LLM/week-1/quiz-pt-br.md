## Tarefa: Questionário 1

**1.** A interação com os modelos de linguagem grande (LLMs) é diferente dos modelos tradicionais de aprendizado de máquina.
Trabalhar com LLMs envolve a entrada de linguagem natural, conhecida como _____, resultando na saída do Large Language Model, conhecido como ______ .

Escolha a resposta que preenche corretamente os espaços em branco.

- [x] prompt, conclusão
- [ ] lLM rápido e ajustado
- [ ] solicitação ajustável, conclusão
- [ ] solicitação de previsão, resposta de previsão

**2.** Os modelos de linguagem grande (LLMs) são capazes de executar várias tarefas que suportam uma variedade de casos de uso.  
Qual das tarefas a seguir suporta o caso de uso de conversão de comentários de código em código executável?

- [x] Tradução
- [ ] Resumo de texto
- [ ] Recuperação de informações
- [ ] Invocar ações a partir do texto

**3.** Qual é a autoatenção que alimenta a arquitetura do transformador?

- [ ] Uma medida de quão bem um modelo pode entender e gerar linguagem semelhante à humana.
- [x] Um mecanismo que permite que um modelo se concentre em diferentes partes da sequência de entrada durante a computação.
- [ ] A capacidade do transformador de analisar seu próprio desempenho e fazer os ajustes necessários.
- [ ] Uma técnica usada para melhorar os recursos de generalização de um modelo treinando-o em diversos conjuntos de dados.

**4.** Quais dos seguintes estágios fazem parte do ciclo de vida do modelo de IA generativo mencionado no curso? (Selecione todos os que se aplicam)

- [x] Manipular o modelo para alinhar-se às necessidades específicas do projeto.
- [ ] Realização de regularização
- [x] Implementar o modelo na infraestrutura e integrá-lo ao aplicativo.
- [x] Seleção de um modelo candidato e possível pré-treinamento de um modelo personalizado.
- [x] Definir o problema e identificar conjuntos de dados relevantes.

**5.** "Os RNNs são melhores que os Transformers para tarefas de IA generativas." 
Isso é verdadeiro ou falso?

- [] Verdadeiro
- [x] Falso

**6.** Qual arquitetura de modelo baseada em transformador tem o objetivo de adivinhar um token mascarado com base na sequência anterior de tokens, criando representações bidirecionais da sequência de entrada.

- [ ] Autoregressivo
- [ ] Sequência a sequência
- [x] Autocodificador

**7.** Qual arquitetura de modelo baseada em transformador é mais adequada para a tarefa de tradução de textos?

- [ ] Autocodificador
- [ ] Autoregressivo
- [x] Sequência a sequência

**8.** É sempre necessário aumentar o tamanho do modelo para melhorar seu desempenho?

- [ ] Verdadeiro
- [x] Falso

**9.** As leis de escalonamento para o pré-treinamento de grandes modelos de linguagem consideram vários aspectos para maximizar o desempenho de um modelo dentro de um conjunto de restrições e opções de escalonamento disponíveis.  O senhor seleciona todas as alternativas que devem ser consideradas para o dimensionamento ao realizar o pré-treinamento do modelo?

- [x] Tamanho do conjunto de dados: Número de tokens
- [x] Tamanho do modelo: Número de parâmetros
- [ ] Tamanho do lote: Número de amostras por iteração 
- [x] Calcular o orçamento: Computar restrições

**10.** "O senhor pode combinar o paralelismo de dados com o paralelismo de modelos para treinar LLMs."
Isso é verdadeiro ou falso?

- [x] Verdadeiro
- [ ] Falso









